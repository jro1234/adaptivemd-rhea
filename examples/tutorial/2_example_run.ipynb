{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2 - `AdaptiveMD` Trajectory and Modelling Tasks\n",
    "\n",
    "`adaptivemd` relies on ansynchronous simulation execution and analysis. The objects introduced in **Tutorial 1** provide the basic interface used to create and organize this kind of work. In **Tutorial 2** we will learn some more about the class `Trajectory` representing trajectory data and introduce a `modeller` task that uses the class `PyEMMAAnalysis`. We will also learn more about the `task` object representing any work, and `worker` objects who take & execute tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reopening a `Project`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from adaptivemd import Project, Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open our tutorial project by its name. If you completed the previous example this should all work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project('tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This opened all connections to the `MongoDB` and `Session` so we can get started. Be sure to have an `adaptivemdworker` running to complete the tasks we queue in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we are. These numbers will depend on when you run this notebook relative to the tasks performed under the project name 'tutorial'. Unless you delete your project, it will accumulate models and files over time, as is our ultimate goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick summary of items in project\n",
      "Tasks : <StoredBundle for with 2 file(s) @ 0x10f95fb50>\n",
      "Trajs : <ViewBundle for with 1 file(s) @ 0x10f95fd10>\n",
      "Models: <StoredBundle for with 0 file(s) @ 0x10f95fa90>\n"
     ]
    }
   ],
   "source": [
    "def print_summary(project):\n",
    "    print(\"Quick summary of items in project\")\n",
    "    print(\"Tasks : %s\" % project.tasks)\n",
    "    print(\"Trajs : %s\" % project.trajectories)\n",
    "    print(\"Models: %s\" % project.models)\n",
    "    \n",
    "print_summary(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restore our old python references to generate tasks by loading the previously used generators via their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = project.generators['openmm']\n",
    "modeller = project.generators['pyemma']\n",
    "pdb_file = project.files['initial_pdb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we stored some files in the database. and of course you can look at them again, should that be important. `File` objects have a method `get_file` for printing the contents of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMARK   1 CREATED WITH MDTraj 1.8.0, 2016-12-22\n",
      "CRYST1   26.063   26.063   26.063  90.00  90.00  90.00 P 1           1 \n",
      "MODEL        0\n",
      "ATOM      1  H1  ACE A   1      -1.900   1.555  26.235  1.00  0.00          H   \n",
      "ATOM      2  CH3 ACE A   1      -1.101   2.011  25.651  1.00  0.00          C   \n",
      "ATOM      3  H2  ACE A   1      -0.850   2.954  26.137  1.00  0.00          H   \n",
      "ATOM      4  H3  ACE A   1      -1.365   2.132  24.600  1.00  0.00          H   \n",
      "ATOM      5  C   ACE A   1       0.182   1.186  25.767  1.00  0.00          C   \n",
      "ATOM      6  O   ACE A   1       1.089   1.407  26.645  1.00  0.00          O   \n",
      "ATOM      7  N   ALA A   2       0.302   0.256  24.807  1.00  0.00          N   \n",
      "ATOM      8  H   ALA A   2      -0.588   0.102  24.354  1.00  0.00          H   \n",
      "ATOM      9  CA  ALA A   2       1.498  -0.651  24.567  1.00  0.00          C   \n",
      "ATOM     10  HA  ALA A   2       1.810  -0.944  25.570  1.00  0.00          H   \n",
      "ATOM     11  CB  ALA A   2       1.054  -1.959  23.852 [...]\n"
     ]
    }
   ],
   "source": [
    "print(pdb_file.get_file()[:1000] + ' [...]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Trajectory` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we talk about adaptivity, let's have a look at possibilities to generate trajectories. We assume that you successfully ran a first trajectory using a worker. Next, we talk about different ways to generate new trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectories from a pdb\n",
    "\n",
    "This will typically be the first step generating data in a project. Remember we already have a PDB stored from setting up the engine. if you want to start from this state, do as before:\n",
    "\n",
    "1. create the `Trajectory` object you want\n",
    "2. make a task to run the simulation\n",
    "3. submit the task so the simulation can run to create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trajectory contains all necessary information to make itself from running the simulation program. It has \n",
    "\n",
    "1. a (hopefully unique) location: This will be the folder where all the associated files go\n",
    "2. an initial frame: the initial state to be used by the MD simulation package\n",
    "3. a length in frames to run\n",
    "4. the `Engine`: the actual MD package used to create the trajectory\n",
    "\n",
    "Note, the `Engine` contains information about the topology and about which output files are generated. This is the essential information you will need for analysis, e.g. what is the filename of the trajectory file that contains the protein structure and what is its stride? Additionally, the `Engine` creates the call to the simulation program, so any other required arguments, file operations, and settings are provided in the object definition. The call is constructed in the `run` and `extend` methods, and contained in the returned `task` objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first build a second `Trajectory` from scratch. In **Tutorial 1** we used the helper method `project.new_trajectory` to create the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = next(project.traj_name)              # get a unique new filename \n",
    "\n",
    "trajectory = Trajectory(\n",
    "    location=file_name,                          # this creates a new filename\n",
    "    frame=pdb_file,                              # initial frame is the PDB\n",
    "    length=100,                                  # length is 100 frames\n",
    "    engine=engine                                # the engine to be used\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect data outside the adaptivemd package, we want to know where the project's trajectories are by their `location`. So when using the convenience function `new_trajectory`, this is set to a folder under the path resolving from `{configuration.shared_path}/{project.name}/trajs/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory2 = project.new_trajectory(\n",
    "    frame=pdb_file,\n",
    "    length=100,\n",
    "    engine=engine,\n",
    "    number=1          # if more then one you get a list of trajectories\n",
    ")\n",
    "#trajectory2 = project.new_trajectory(pdb_file, 100, engine, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the first example, now that we have the parameters of the `Trajectory` we can create the task to run simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Task` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_run = trajectory.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was easy, but we can do some interesting stuff. Since we know the trajectory will exist now we can also extend by some frames. Remember, the trajectory does not really exist yet (not until we submit it and a worker executes it), but we can pretend that it does, since it's relevant propertier are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_extend = trajectory.extend(50)\n",
    "# Q: if you repeat, does this grow longer?\n",
    "# H: consider that you are calling from same object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only problem is to make sure the tasks are run in the correct order. This would not be a problem if the worker will run tasks in the order they are place in the queue, but that defeats the purpose of parallel runs. Therefore an extended tasks knows it is dependent on the existance of the source trajectory. The `worker` will hence only run a trajectory once the source exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency in the project queue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wonder at this point how we manage to construct the dependency graph between all tasks and how this is handled and optimized, etc... \n",
    "\n",
    "Well, we don't. There is no dependency graph, at least not explicitely. Instead we check at some time among all tasks that _should_ be run, which _can_ be run. And this is easy to check, all dependent tasks need to be completed and must have succeeded. Then we can rely on their (the dependencies) results to exists and it makes sense to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A real dependency graph would go even further and know about all future relations and you could identify bottleneck\n",
    "tasks which are necessary to allow other tasks to be run. We don't do that (yet). It could improve performance in the sense that you will run at optimal load balance and keep all workers as busy as possible. Consider our a attempt a first order dependency graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.queue(task_run, task_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on simulation length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we allow an engine to output multiple trajectory types with freely chosen strides? This could leads to some difficulty indexing frames in the trajectory. Imagine this (unrealistic) situation: \n",
    "\n",
    "We have\n",
    "1. full trajectory with `stride=10`\n",
    "2. a reduced protein-only trajectory with `stride=7`\n",
    "\n",
    "Now run a trajectory of `length=300`.\n",
    "We get \n",
    "\n",
    "1. 30+1 full (+1 for the initial frame) and\n",
    "2. 42+1 protein frames\n",
    "\n",
    "That per se is no problem, but if you want to extend we only have a restart file for the very last frame and while this works for the full trajectory, for the protein trajectory you are 6 frames short. Just continuing and concatenating the two leads to a gap of 6+7=13 frames instead of 7. A small but potentially significant source of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, compute the least common multiple of all strides using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.native_stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chained Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a shorter way of writing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task = trajectory.run().extend(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will run as two tasks that first runs the trajectory and then extend it by 50 frames (in native engine frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do that several times, you can pass a list of ints which is a shortcut for calling `.extend(l1).extend(l2). ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e779420a5801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO this doesnt work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# does it make sense? see Q/H above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/osz/adaptivemd/adaptivemd/engine/engine.pyc\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, length, export_path)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# this is not really necessary since we require internally that the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/osz/adaptivemd/adaptivemd/engine/openmm/openmm.pyc\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, source, length, resource_name, export_path, cpu_threads, gpu_contexts, mpi_rank)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# create a new file, but with the same name, etc, just new length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         t = TrajectoryExtensionTask(self, target, source, cpu_threads=cpu_threads,\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "# TODO this doesnt work\n",
    "# does it make sense? see Q/H above\n",
    "task = trajectory.run().extend([10] * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create 10! tasks that each extend the previous one. Each of the task requires the previous one to finish, this way the dependency is preserved. You can use this to mimick using several restarts in between, we don't know which worker will actually start and which worker will continue or finish a trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if everything is going as we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox:///{}/00000000/ 100\n",
      "sandbox:///{}/00000001/ 150\n"
     ]
    }
   ],
   "source": [
    "for t in project.trajectories:\n",
    "    print(t.short, t.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this works, then you should see one 100 frame trajectory from the setup (first example) and a second 150 length trajectory that we just generated by running 100 frames and extending it by another 50.\n",
    "\n",
    "If not, there might be a problem or (more likely) the tasks are not finished yet. Just try the above cell again and see if it changes to the expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`project.trajectories` will show you _only_ existing trajectories. Not ones, that are planned or have been extended. If you want to see all the ones already in the project, you can look at `project.files`. Which is a bundle and bundles can be filtered. But first all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/osz/adaptivemd/adaptivemd/scripts/_run_.py\n",
      "file:///Users/osz/adaptivemd/adaptivemd/engine/openmm/openmmrun.py\n",
      "file:///Users/osz/adaptivemd/examples/files/alanine/alanine.pdb\n",
      "file:///Users/osz/adaptivemd/examples/files/alanine/system.xml\n",
      "file:///Users/osz/adaptivemd/examples/files/alanine/integrator.xml\n",
      "sandbox:///projects/tutorial/trajs/00000000/\n",
      "sandbox:///projects/tutorial/trajs/00000001/\n",
      "sandbox:///projects/tutorial/trajs/00000001/\n"
     ]
    }
   ],
   "source": [
    "for f in project.files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all files filtered by class `Trajectory`. `DT` is a little helper to convert time stamps into something readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptivemd import DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox:///{}/00000000/ 100\n",
      "created  @ 2018-08-02 13:25:55, True\n",
      "sandbox:///{}/00000001/ 100\n",
      "modified @ 2018-08-02 13:28:59, False\n",
      "sandbox:///{}/00000001/ 150\n",
      "created  @ 2018-08-02 13:28:59, True\n"
     ]
    }
   ],
   "source": [
    "for t in project.files.c(Trajectory):\n",
    "    print(t.short, t.length)\n",
    "    if t.created:\n",
    "        if t.created > 0:\n",
    "            print('created  @ %s, %s' % (DT(t.created), t.exists))\n",
    "        else:\n",
    "            print('modified @ %s, %s' % (DT(-t.created), t.exists))\n",
    "    else:\n",
    "        print('not existent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the extended trajecory appears twice once with length 100 and once with length 150. This is correct, because the 100 frame trajectory was used and hence saved as a `File` in the database. But why does this one not appear in the list of trajectories? It was created first and had a timestamp of creation written to `.created`. This is the time when the worker finishes and was successful. \n",
    "\n",
    "When a file is overwritten, it is marked as modified by setting a negative timestamp. So if \n",
    "\n",
    "1. `trajectory.created is None`, the file does not exist nor has it.  \n",
    "2. `trajectory.created > 0`, the file exists\n",
    "3. `trajectory.created < 0`, the file existed but was overwritten to extend length\n",
    "\n",
    "The `project.trajectories` `ViewBundle` contains files of type `Trajectory` with positive `created` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000: 100, exists? True\n",
      "00000001: 150, exists? True\n"
     ]
    }
   ],
   "source": [
    "for t in project.trajectories:\n",
    "    print(\"%s: %d, exists? %s\" % (t.basename, t.length, t.exists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trajectory` reference we have now refers to a non-existing directory, because it was overwritten and a concatenated trajectory object of length 150 is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun let's produce an error by using a wrong initial pdb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = project.new_trajectory(engine['system_file'], 100)\n",
    "task = engine.run(trajectory)\n",
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, nothing seems changed here but we expect the task to fail. So let's inspect what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'fail'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to execute this cell several times. It will first become `queued`, then `running` and finally `fail` and stop there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It failed as we knew it would. No suprise here, but why? Let's look at the stdout and stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:29:17 [worker:3] stdout from running task\n",
      "GO...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:29:17 [worker:3] stderr from running task\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dcd import DCDTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .binpos import BINPOSTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .xtc import XTCTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .trr import TRRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:15: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dtr import DTRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tng import TNGTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/__init__.py:54: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._lprmsd import lprmsd\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/geometry/angle.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from mdtraj.geometry import _geometry, distance\n",
      "Traceback (most recent call last):\n",
      "  File \"openmmrun.py\", line 255, in <module>\n",
      "    args.system_xml, args.integrator_xml)\n",
      "  File \"openmmrun.py\", line 118, in read_input\n",
      "    returns.update({op_name: func(arg)})\n",
      "  File \"openmmrun.py\", line 87, in get_pdbfile\n",
      "    raise IOError(\"{} must end in '.pdb' for reading as PDB file\".format(topology_pdb))\n",
      "IOError: coordinates.xml must end in '.pdb' for reading as PDB file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see what we expect. In `openmmrun.py` the openmm executable could not load the pdb file. \n",
    "\n",
    "> *NOTE* If your worker dies for some reason, it will not set a STDOUT or STDERR. If you think that your task should be able to execute, then you can do `task.state = 'created'` and reset it to be accessible to workers. This is NOT recommended, just to explain how this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about the `Trajectory` Objects\n",
    "\n",
    "If you have a `Trajectory` object and create the real trajectory file, you can also put the `Trajectory` directly into the queue. This is equivalent to call `.run` on the trajectory and submit the resulting `Task` to the queue. To check it's status, etc..., work with a corresponding `Task` object. One thing to note is that extending from a specific trajectory using the same `trajectory` object reference will currently result in overwritten extensions and lost data, along with incorrect storage of `Trajectory` files in `project.trajectories`. Be sure to either use `task.extend` or iterate through `project.trajectories` to extend existing trajectories, which will properly update the `created` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.queue(project.new_trajectory(pdb_file, 100, engine).run()) can be called as\n",
    "project.queue(project.new_trajectory(pdb_file, 100, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectories from other trajectory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the most common case. At least in any remote kind of adaptivity you will not start always from the same position or extend. You want to pick any exisiting frame and continue from there. So, let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get a trajectory. Every `Bundle` in the project (e.g. `.trajectories`, `.models`, `.files`, `.tasks`) acts like an enhanced set. You can iterate over all entries as we did before, and you can get one element, which usually is the first stored, but not always. If you are interested in `Bundle`s see the documentation. For now that is enough to know, that a bundle (as a set) has a `.one` function which is short for getting the first object if you iterate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = project.trajectories.one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, at least 100 frames. We pick, say, frame at index 28 (which is the 29th frame, we start counting at zero) using the way you pick an element from a python list (which is almost what a `Trajectory` represents, a list of frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame(sandbox:///{}/00000000/[28]) False\n"
     ]
    }
   ],
   "source": [
    "frame = trajectory[28]\n",
    "print(frame, frame.exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame(sandbox:///{}/00000000/[30]) True\n"
     ]
    }
   ],
   "source": [
    "frame = trajectory[30]\n",
    "print(frame, frame.exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is important! We are running only one full atom trajectory with stride larger than one, so if we want to pick a frame from this trajectory you can pick in theory every frame, but only some of these really exist. If you want to restart from a frame this needs to be the case. Otherwise you run into trouble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a trajectory just use the frame as the initial frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "frame = trajectory[28]\n",
    "task = project.new_trajectory(frame, 100, engine).run()\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adaptivemd.engine.engine.TrajectoryGenerationTask object at 0x10482aa50>\n"
     ]
    }
   ],
   "source": [
    "frame = trajectory[30]\n",
    "task = project.new_trajectory(frame, 100, engine).run()\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: TrajectoryGenerationTask(OpenMMEngine) [created]\n",
      "\n",
      "Sources\n",
      "-- Unstaged\n",
      "- sandbox:///{}/00000000/ [exists]\n",
      "-- Staged\n",
      "- staging:///integrator.xml \n",
      "- staging:///system.xml \n",
      "- staging:///openmmrun.py \n",
      "- staging:///alanine.pdb \n",
      "\n",
      "Targets\n",
      "- sandbox:///{}/00000006/\n",
      "\n",
      "Modified\n",
      "\n",
      "Link('staging:///alanine.pdb' > 'worker://initial.pdb)\n",
      "Link('staging:///system.xml' > 'worker://system.xml)\n",
      "Link('staging:///integrator.xml' > 'worker://integrator.xml)\n",
      "Link('staging:///openmmrun.py' > 'worker://openmmrun.py)\n",
      "Link('sandbox:///{}/00000000/' > 'worker://source/)\n",
      "mdconvert -o worker://input.pdb -i 3 -t worker://initial.pdb worker://source/master.dcd\n",
      "Touch('worker://traj/')\n",
      "\n",
      "j=0\n",
      "tries=10\n",
      "sleep=1\n",
      "\n",
      "trajfile=traj/protein.dcd\n",
      "\n",
      "while [ $j -le $tries ]; do if ! [ -s $trajfile ]; then python openmmrun.py -r --report-interval 1 -p CPU --types=\"{'protein':{'stride':1,'selection':'protein','name':null,'filename':'protein.dcd'},'master':{'stride':10,'selection':null,'name':null,'filename':'master.dcd'}}\" -s system.xml -i integrator.xml -t worker://input.pdb --length 100 worker://traj/; fi; sleep 1; j=$((j+1)); done\n",
      "Move('worker://traj/' > 'sandbox:///{}/00000006/)\n"
     ]
    }
   ],
   "source": [
    "print(task.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, how the actual frame picked in the `mdconvert` line is `-i 3` meaning index 3 which represents frame 30 with stride 10.\n",
    "\n",
    "Now, run the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One helpful tool you can use to wait until something happens is the method `project.wait_until(condition)`. This is not so useful in notebooks, but in scripts it can be used to synchronize events in the workflow. `condition` here is a function that evaluates to `True` or `False`. It will be tested in regular intervals, and once it is `True`, the `wait_until` function returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533230755.345511"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory.created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now wait until all events are finished. This method takes a condition and blocks until the condition is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.wait_until(task.is_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'success'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:30:45 [worker:3] stderr from running task\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dcd import DCDTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .binpos import BINPOSTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .xtc import XTCTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .trr import TRRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:15: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dtr import DTRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tng import TNGTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/__init__.py:54: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._lprmsd import lprmsd\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/geometry/angle.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from mdtraj.geometry import _geometry, distance\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dcd import DCDTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .binpos import BINPOSTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .xtc import XTCTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .trr import TRRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:15: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dtr import DTRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tng import TNGTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/__init__.py:54: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._lprmsd import lprmsd\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/geometry/angle.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from mdtraj.geometry import _geometry, distance\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/utils/validation.py:116: TypeCastPerformanceWarning: Casting xyz dtype=float64 to <type 'numpy.float32'> \n",
      "  TypeCastPerformanceWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Task` has a function `is_done` that you can use. It will return if a task is done. That means it either failed or succeeded or was cancelled. Basically when it is not queued anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run adaptively, _all you need to do_ is to figure out where to start new simulations from and use the methods provided to run these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Model` Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are of course other things you can do besides creating new trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptivemd.analysis.pyemma import PyEMMAAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model generating task works similar to trajectories. You create the generator with options  and then you create a `Task` from passing it a list of trajectories to be analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance to compute an MSM model of trajectories that you pass it. It is initialized with a `.pdb` file that is used to define the topology. The `features` argument will be converted to a PyEMMA MDFeaturizer object. More on that later. The other two option chose which output type from the engine we want to analyse. We chose the protein trajectories since these are faster to load and have better time resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeller = PyEMMAAnalysis(\n",
    "    engine=engine,\n",
    "    outtype='protein',\n",
    "    features={'add_inverse_distances': {'select_Backbone': None}}\n",
    ").named('pyemma')\n",
    "\n",
    "#modeller = project.generators['pyemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we name it `pyemma` for later reference. By the way, we now have a couple analysis generators with same parameters and name, but since they are different objects they can all be stored. Be careful with names...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = modeller.execute(list(project.trajectories))\n",
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.wait_until(task.is_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:31:51 [worker:3] stderr from running task\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/dense/__init__.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mle_trev\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/dense/__init__.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mle_trev_given_pi\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/dense/tmatrix_sampler.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . sampler_rev import SamplerRev\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/dense/tmatrix_sampler.py:39: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . sampler_revpi import SamplerRevPi\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/sparse/__init__.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mle_trev_given_pi\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/msmtools/estimation/sparse/__init__.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mle_trev\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/bhmm/output_models/discrete.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from bhmm.output_models.impl_c import discrete as dc\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/bhmm/output_models/gaussian.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from bhmm.output_models.impl_c import gaussian as gc\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/bhmm/hidden/impl_c/__init__.py:3: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from bhmm.hidden.impl_c.hidden import *\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import bar\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import wham\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mbar\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import tram\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import dtram\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import mbar_direct\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/thermotools/__init__.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import tram_direct\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/pyemma/thermo/estimators/TRAM_estimator.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from thermotools import trammbar as _trammbar\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/pyemma/thermo/estimators/TRAM_estimator.py:34: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from thermotools import trammbar_direct as _trammbar_direct\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dcd import DCDTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .binpos import BINPOSTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .xtc import XTCTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .trr import TRRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:15: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .dtr import DTRTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/formats/__init__.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tng import TNGTrajectoryFile\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/__init__.py:54: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._lprmsd import lprmsd\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/mdtraj/geometry/angle.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from mdtraj.geometry import _geometry, distance\n",
      "/Users/osz/admd/miniconda3/envs/admdenv/lib/python2.7/site-packages/pyemma/__init__.py:134: UserWarning: Python 2.7 usage is deprecated. Future versions of PyEMMA will not support it. Please upgrade your Python installation.\n",
      "  \"Please upgrade your Python installation.\", category=UserWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:31:51 [worker:3] stdout from running task\n",
      "02-08-18 13:31:49 pyemma.coordinates.data.featurization.featurizer.MDFeaturizer[0] WARNING  The 1D arrays input for add_inverse_distances() have been sorted, and index duplicates have been eliminated.\n",
      "Check the output of describe() to see the actual order of the features\n",
      "#trajectories : 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above modeller is used without storing first, and it becomes stored when queueing the task. Now, when you try to get a generator by name \"pyemma\", you can't be sure what you'll get. To show this, we use the `c` method on generator `StoredBundle` to see all the modellers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144792017792079339759055817894162071954\n",
      "pyemma 297636284461269466507679179728245227624\n",
      "pyemma 144792017792079339759055817894162071954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(modeller.__uuid__)\n",
    "[print(g.name, g.__uuid__) for g in project.generators.c(PyEMMAAnalysis)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adaptivemd.model.Model object at 0x104813b10>\n"
     ]
    }
   ],
   "source": [
    "for m in project.models:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we generated one model. The `Model` objects contains (in the base version) a `.data` attribute, which is a dictionary of information about the generated model. As usual, a `keys` method can show you what data you can access. Let's look at the transition probability matrix $P$ and count matrix $C$ calculated from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = project.models.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84444444 0.         0.0887199  0.         0.         0.\n",
      "  0.06683566]\n",
      " [0.         0.78787879 0.         0.04363512 0.05329142 0.11519466\n",
      "  0.        ]\n",
      " [0.09273342 0.         0.74074074 0.         0.01523732 0.0883101\n",
      "  0.06297842]\n",
      " [0.         0.02489071 0.         0.77777778 0.         0.\n",
      "  0.19733152]\n",
      " [0.         0.04493231 0.03567226 0.         0.75757576 0.16181967\n",
      "  0.        ]\n",
      " [0.         0.05959917 0.12686411 0.         0.09929738 0.63157895\n",
      "  0.08266039]\n",
      " [0.07129277 0.         0.06427081 0.12714431 0.         0.05872068\n",
      "  0.67857143]]\n"
     ]
    }
   ],
   "source": [
    "print(model['msm']['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0.,  5.],\n",
       "       [ 0., 52.,  0.,  0.,  0.,  2.,  0.,  3.,  9.,  0.],\n",
       "       [ 0.,  0., 32.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 7.,  0.,  0., 40.,  0.,  0.,  0.,  0.,  4.,  3.],\n",
       "       [ 0.,  0.,  0.,  0., 17.,  0.,  6.,  0.,  0.,  0.],\n",
       "       [ 0.,  2.,  0.,  0.,  0., 35.,  0.,  0.,  0.,  8.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  0., 25.,  0.,  0.,  0.],\n",
       "       [ 0.,  2.,  2.,  2.,  0.,  0.,  0., 25.,  4.,  0.],\n",
       "       [ 0.,  2.,  0.,  8.,  0.,  0.,  0.,  7., 36.,  4.],\n",
       "       [ 2.,  0.,  0.,  4.,  0.,  8.,  0.,  0.,  4., 38.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data['msm']['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick frames automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing that we are covering here is a function that can utilize models to decide which frames are better to start from. The simplest one will use the counts per state, take the inverse and use this as a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Frame(sandbox:///{}/00000004/[10]),\n",
       " Frame(sandbox:///{}/00000006/[100]),\n",
       " Frame(sandbox:///{}/00000001/[80]),\n",
       " Frame(sandbox:///{}/00000004/[60])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.find_ml_next_frame(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can pick states according to the newest (last) model. (This will be moved to the Brain). And since we want trajectories with these frames as starting points there is also a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trajectory(Frame(sandbox:///{}/00000000/[50]) >> 00000007[0..100]),\n",
       " Trajectory(Frame(sandbox:///{}/00000006/[90]) >> 00000008[0..100]),\n",
       " Trajectory(Frame(sandbox:///{}/00000006/[20]) >> 00000009[0..100]),\n",
       " Trajectory(Frame(sandbox:///{}/00000006/[70]) >> 00000010[0..100])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories = project.new_ml_trajectory(length=100, number=4, engine=engine)\n",
    "trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit these before we finish this notebook with a quick discussion of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.queue(trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Worker` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Worker` instances execute tasks for you. If you did not stop the worker in the command line it will still be running and you can check its state. Here we use the `m` method to filter stored objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[running- 13:32:24] sampion:/Users/osz\n"
     ]
    }
   ],
   "source": [
    "project.trigger()\n",
    "for w in project.workers.m('state','running'):\n",
    "#for w in project.workers:\n",
    "#    if w.state == 'running':\n",
    "        print('[%s- %s] %s:%s' % (w.state, DT(w.seen).time, w.hostname, w.cwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the worker is running, was last reporting its heartbeat at ... and has a hostname and current working directory (where it was executed from). The generators specify which tasks from some generators are executed. If it is `None` then the worker runs all tasks it finds. You can use this to run specific workers for models and some for trajectory generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also control it remotely by sending it a command. `shutdown` will shut it down for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# project.workers.last.command = 'shutdown'\n",
    "# Note that waiting for all trajs to exist is not\n",
    "# generally a good progress mechanism\n",
    "#  --> no break on task failure\n",
    "project.wait_until(lambda: all([tj.exists for tj in trajectories]))\n",
    "project.workers.all.execute(\"shutdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards you need to restart you worker to continue with this examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
