#!/usr/bin/env python

'''
    Usage:
           $ python run_admd.py [name] [additional options]

'''

import os
_cwd_ = os.getcwd()

import sys
import time
import datetime
import traceback
from pprint import pformat

from adaptivemd import PythonTask, Task
from adaptivemd.runtime import get_argparser, initialize_project, workflow_generator_simple, create_workload_launcher
from adaptivemd.util import get_logger
logger = get_logger(logname=__name__)


# Exit codes from this script are NOT conventional!
#
# negative: an error
#
# zero:     no error
#
# positive: the integer number of tasks that were found to
#           have (erroneously) not completed

# FIXME these should be organized within the AdaptiveMD Task object
final_states    = Task.FINAL_STATES + Task.RESTARTABLE_STATES
created_state   = 'created'
created_update  = {"state":created_state, "__dict__.state":created_state}
fix_states      = {'queued','running','fail','failed','cancelled','pending'}
runnable_states = set(fix_states)
runnable_states.add(created_state)

task_done = lambda ta: ta.state in final_states
is_incomplete = lambda ta: ta.state in runnable_states


if __name__ == '__main__':

    project = None
    sleeptime = 1

    try:

        _exitval_ = -1

        parser   = get_argparser()
        args     = parser.parse_args()

        submit_only = args.submit_only

        logger.info("Initializing Project named: " + args.project_name)
        logger.info("Recieved Argumentes:\n{}".format(args))
        logger.info("Project opening")
        logger.debug("with config %s"%args.config)

        project = initialize_project(
            args.project_name,
            sys_name = args.system_name,
            m_freq   = args.all,
            p_freq   = args.prot,
            platform = args.platform,
            features = None,
            config   = args.config,
        ) 

        logger.debug("Project opened")
        logger.info(
            "AdaptiveMD dburl: {}".format(project.storage._db_url))

        logger.info(
            "number of project.trajectories: {}".format(
                len(project.trajectories)))

        logger.info(
            "number of project.models: {}".format(
                len(project.models)))

        # TODO not clear on relationship of these and embedded conditions
        if args.rescue_tasks or args.rescue_only:

            rescue_tasks = list(filter(is_incomplete, project.tasks))
            rescue_uuids = list(map(lambda ta: ta.__uuid__, rescue_tasks))
            n_incomplete_tasks = len(rescue_tasks)

            if n_incomplete_tasks:

                _exitval_ = n_incomplete_tasks
                logger.info(
                  "Exiting to rescue {} incomplete tasks".format(_exitval_)
                )
                sys.exit(_exitval_)

            elif args.rescue_only:

                _exitval_ = 0
                logger.info("All tasks rescued, exiting with no action")
                sys.exit(_exitval_)

            # TODO what is happening here?
            else:
                logger.info(
                    "Proceeding after rescue check, found {} incomplete tasks".format(
                    n_incomplete_tasks)
                )

        else:
            logger.info(
                "No rescue check performed, found {} incomplete tasks".format(
                n_incomplete_tasks)
            )

        if args.init_only:
            logger.info("Leaving project '{}' initialized without tasks".format(
                project.name)
            )

            _exitval_ = 0

        else:
            logger.info("Configuring workload")

            n_traj   = 0
            modeller = None

            if not args.rescue_only:
                # TODO we currently only support a single simulation configuration
                #      with the runtime system.
                engine   = project.generators["openmm"]
                n_traj   = args.n_traj
                n_rounds = args.n_rounds # n_rounds in single runtime, almost always 1
                round_n  = args.round_n   # round number for overall workflow
                length   = args.length
                model_tasks = list(project.tasks.c(PythonTask).m('state','created'))

                # We support multiple modellers so that analysis using
                # different featurization can be evaluated easily
                if args.modeller:
                    nm_modeller = args.modeller
                    modeller = project.generators[nm_modeller]

            else:
                logger.info(
                    "Looking to clean up unfinished tasks: task states: {}".format(
                    project.task_states))

                # TODO FIXME this approach for resetting task states not acceptable for general use...
                #            in the future a single adaptivemd project instance should be able to
                #            coordinate multiple workloads simultaneously, and this introduces race
                #            conditions since we are in no way trying to target the reset action to
                #            specific groups of tasks, i.e. by their resource, round number (isn't
                #            stored yet anyways), etc
                for fix_state in fix_states:
                    project.tasks._set._document.update_many(
                        {"state": fix_state},
                        {"$set" : created_state_update}
                    )

                logger.info(
                    "After fixes: task states: {}".format(
                    project.task_states))

                #project.tasks._set.clear_cache()
                #project.tasks._set.load_indices()
                #logger.info("After reload: observed task states: {}".format(project.task_states))

                new_tasks = project.tasks.v(
                    lambda ta: ta.__uuid__ in rescue_uuids)

                model_tasks += list(new_tasks.c(PythonTask))

                # FIXME list elements getting duplicated somehow
                # TODO  see if this still happens ^^^
                new_tasks = list(set(new_tasks))
                model_tasks = list(set(model_tasks))
                logger.info(
                    "Found {} tasks to execute in cleanup".format(
                    len(new_tasks)))

                if not new_tasks:

                    logger.info((
                        "Checked for failed tasks to rescue but "
                        "found none, exiting without error"))

                    _exitval_ = 0
                    print(_exitval_)
                    sys.exit(_exitval_)

                n_rounds  = 1

                #for ta in new_tasks:
                #    logger.info("{0}  {1}".format(ta.state, getattr(ta, 'trajectory', None)))

                # FIXME get the number of MD steps to be run in the task, not total MD length
                #       and use this for the length argument to generator function
                #if any([hasattr(ta, 'trajectory') for ta in new_tasks]):
                #    # doesn't handle TrajectoryExtensionTask correctly
                #    length    = max(map(lambda ta: ta.trajectory.length, filter(lambda ta: hasattr(ta,'trajectory'), new_tasks)))

            sfkwargs = dict()
            sfkwargs['num_macrostates'] = 25
            logger.info("n_rounds: {}".format(n_rounds))

            if n_traj or modeller:

                # We're going to track what happens with new tasks that
                # get generated next, need to capture current inventory
                existing_tasks = [ta.__uuid__ for ta in project.tasks]
                logger.info(
                    "Project adding event from {}".format(
                    workflow_generator_simple))

                project.add_event(workflow_generator_simple(
                    project, engine, n_traj, args.n_ext, length, round_n,
                    longest = args.all,
                    n_rounds = n_rounds,
                    modeller = modeller,
                    sfkwargs = sfkwargs,
                    minlength = args.minlength,
                    batchsize = args.batchsize,
                    batchwait = args.batchwait,
                    batchsleep = args.batchsleep,
                    progression = args.progression,
                    cpu_threads = args.threads,
                    fixedlength = True,#args.fixedlength,
                    startontraj = args.after_n_trajs,
                    admd_profile = args.rc,
                    min_model_trajlength = args.min_model_trajlength,
                    sampling_function_name = args.sampling_method,
                ))

                new_tasks = list(filter(
                    lambda ta: ta.__uuid__ not in existing_tasks, project.tasks))

            else:

                logger.info(
                    "Project event adding from incomplete tasks\n{}".format(
                    new_tasks))
                sleeptime = 20
                logger.debug("These are the tasks being cleaned up:")
                logger.debug(pformat(new_tasks))
                project.add_event(all([ta.is_done() for ta in new_tasks]))

            logger.info("Project event added")
            _exitval_ = 0

            if submit_only:

                # TODO calculate_request via resource configuration and args
                wl, session = create_workload_launcher(project, new_tasks, args, _cwd_)
                logger.debug(pformat(wl.job_configuration))
                wl.launch_job(session)

            else:
                logger.info("Project waiting on completion event for last workload")
                project.wait_until(project.events_done)
                logger.info("Project event done")

    except KeyboardInterrupt:

        _exitval_ = -2

        logger.warning("ADAPTIVEMD KEYBOARD INTERRUPT- Quitting Workflow Execution")

    except Exception as e:

        _exitval_ = -1

        logger.error("Error during workflow: {}".format(e))
        logger.error(traceback.print_exc())

    finally:

        os.chdir(_cwd_)

        if project:
            project.resources.consume_one()
            project.close()
            logger.info("Project closed")

         #   if not args.init_only and dump_finalize_timestamps:
         #       final_timestamps = pull_final_timestamps(project)
         #       logger.info(pformat(final_timestamps))

        logger.info("Exiting Event Script")

        #if len(project.workers) > 0:
        #    logger.info("Sending 'shutdown' command to all active workers")
        #    logger.info(project.workers.all)
        #    project.workers.all.execute('shutdown')

        print(_exitval_)
        sys.exit(_exitval_)

